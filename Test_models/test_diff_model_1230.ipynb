{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys \n",
    "sys.path.append(\"..\") \n",
    "from model.dataset import *\n",
    "from model.GaussianDiffusion_new1228 import GaussianDiffusion #可以自己调\n",
    "\n",
    "from metrics_calculate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看生成图片，定性描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已加载\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1'\n",
    "model_path = \"./DiffusionSpinalMRISynthesis/model_save/diffusion_model.pth\"\n",
    "net_G = torch.load(model_path, map_location=device)['model'] #['model']\n",
    "\n",
    "# # 这样可以固定随机数种子\n",
    "# net_G = GaussianDiffusion(\n",
    "#     image_size=256,\n",
    "#     model = net_G.model,\n",
    "#     timesteps = 1000,           # number of steps\n",
    "#     sampling_timesteps = 16,    # using ddim for faster inference \n",
    "#     objective = 'pred_v', #pred_v pred_x0崩 pred_noise\n",
    "\n",
    "# ).to(device)\n",
    "net_G.eval()\n",
    "print(\"模型已加载\")\n",
    "\n",
    "spinal_test_dir = \"./DiffusionSpinalMRISynthesis/Data_MRI/test_spinal_MRI\"\n",
    "test_spinal_dataset = MRI_patient_Dataset_fortest(dir_path=spinal_test_dir)\n",
    "test_spinal_dataloader = DataLoader(test_spinal_dataset, batch_size=64, shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要定量描述，把所有测试集的图片测试一遍，计算指标！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_batch(batch_data: torch.Tensor, device= device):\n",
    "    return (batch_data[:,:3,:,:].to(device), batch_data[:,3:,:,:].cpu().detach())\n",
    "\n",
    "def Test_model_metrics(net_G:GaussianDiffusion, test_dataloader):\n",
    "    df_metrics = {'AUC':[],'MSE':[], 'SSIM':[], 'PSNR':[]} #\n",
    "    # df_metrics = []\n",
    "    net_G.eval()\n",
    "    for idx, batch_data in enumerate(tqdm(test_dataloader), 1):\n",
    "        input_img, target_img = get_data_from_batch(batch_data)\n",
    "        with torch.no_grad():\n",
    "            fake_img = net_G.ddim_sample(shape =target_img.shape, source_img = input_img.to(device), \n",
    "                sampling_timesteps = 16, random_seed=42).squeeze(dim=1).detach().cpu().numpy()\n",
    "            # fake_img = nn.Tanh()(fake_img).detach().cpu().numpy()\n",
    "        # 在-1+1 maxminnorm计算全局指标\n",
    "        AUC, MSE, SSIM, PSNR= cal_metric_list(fake_img, target_img.squeeze(dim=1).numpy(), method='8bit', norm=True)\n",
    "        df_metrics['AUC'].extend(AUC)\n",
    "        df_metrics['MSE'].extend(MSE)\n",
    "        df_metrics['SSIM'].extend(SSIM)\n",
    "        df_metrics['PSNR'].extend(PSNR)\n",
    "        # df_metrics['NRMSE'].extend(NRMSE)\n",
    "        \n",
    "    df_metrics = pd.DataFrame(df_metrics)\n",
    "    print(df_metrics.mean())\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = Test_model_metrics(net_G, test_spinal_dataloader)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"./DiffusionSpinalMRISynthesis/Test_models/metrics/diffusion_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.read_csv(\"./DiffusionSpinalMRISynthesis/Test_models/metrics/diffusion_test.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df_metrics_sum = pd.concat([metrics_df.mean(axis=0), metrics_df.std(axis=0)], axis=1).rename(columns={0:'metrics_mean', 1:'metrics_std'})\n",
    "df_metrics_sum.to_csv(\"./DiffusionSpinalMRISynthesis/Test_models/metrics/diffusion_1231_randomseed42_test_sum.csv\")\n",
    "df_metrics_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinal_test_dir = \"./DiffusionSpinalMRISynthesis/Data_MRI/test_spinal_MRI\"\n",
    "output_path = \"./DiffusionSpinalMRISynthesis/results_output_pictures/diffusion_500epoch_test_spinal_16ddim\"\n",
    "\n",
    "def Test_model_onepatient(net_G:GaussianDiffusion, patient_id, output_path=output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    # os.makedirs(output_npy_path, exist_ok=True)\n",
    "    fnames = glob(os.path.join(spinal_test_dir, '*'+patient_id+'*'))\n",
    "    test_onepatient_dataset = MRI_patient_Dataset_fortestpatient(dir_path=spinal_test_dir, patient_id=patient_id)\n",
    "    net_G.eval()\n",
    "    input_img = torch.concat([test_onepatient_dataset[i][[0,1,2],:,:].unsqueeze(dim=0) for i in range(len(test_onepatient_dataset))],dim=0)\n",
    "    target_img = torch.concat([test_onepatient_dataset[i][3:,:,:].unsqueeze(dim=0) for i in range(len(test_onepatient_dataset))],dim=0)\n",
    "    with torch.no_grad():\n",
    "        fake_img = net_G.ddim_sample(shape =target_img.shape, source_img = input_img.to(device), \n",
    "            sampling_timesteps = 16, random_seed=666).squeeze(dim=1)\n",
    "    fake_img = nn.Tanh()(fake_img).detach().cpu().numpy()\n",
    "    fake_img_norm = norm_layerHW(fake_img, method='8bit')\n",
    "    # target_img = norm(target_img.detach().cpu().squeeze(dim=1).numpy())\n",
    "    # output_img = np.concatenate([target_img, fake_img], axis=-1)\n",
    "    patient_save_path = os.path.join(output_path, patient_id)\n",
    "    # patient_npy_save_path = os.path.join(output_npy_path, patient_id)\n",
    "    os.makedirs(patient_save_path, exist_ok=True)\n",
    "    # os.makedirs(patient_npy_save_path, exist_ok=True)\n",
    "    for i in range(fake_img.shape[0]):\n",
    "        img = Image.fromarray(fake_img_norm[i,:,:])\n",
    "        i_savepath = os.path.join(patient_save_path, patient_id+'_T1CE_pred_'+fnames[i].split('_')[-1])\n",
    "        img.save(i_savepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id_list = list(set([path.split('_')[0]+'_'+path.split('_')[1]+'_'+path.split('_')[2] for path in os.listdir(spinal_test_dir)]))\n",
    "for patient_id in tqdm(patient_id_list):\n",
    "    Test_model_onepatient(net_G = net_G, patient_id = patient_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
